# Порівняння ML-моделей (Лабораторна робота для предмету "Методи і моделі машинного навчання")

## Опис 
**Завдання**: бінарна класифікація текстів (спам vs. не спам)
**Тренувальні дані**: [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)
**Класифікатори**: 
1. [Наївний Баєс](bayes.ipynb) 
2. [Випадковий ліс](random_forest.ipynb)
3. [Логістична регресія](logistic_regression.ipynb)
4. [Секвенційна нейронна мережа + DistilBERT](nn_with_bert.ipynb)

## Аналіз результатів 
### Метрики 

| Назва моделі                | Accuracy | Precision | Recall | f1 score |
| --------------------------- | ---------| ----------| -------| ---------|
| Наївний Баєс                | 0.81     | 0.35      | 0.46   | 0.4      |
| Випадковий ліс              | 0.94     | 0.94      | 0.55   | 0.7      |     
| Логістична регресія         | 0.86     | 0.21      | 0.27   | 0.05     |
| Нейронна мережа             | 0.98     | 0.97      | 0.91   | 0.94     |

Як бачимо, найкращі результати показала нейронна мережа, де інпутом були ембедінги, створені моделлю distilBERT (це менша версія BERT, що містить на 40% менше параметрів). Пояснити це можна таким чином:
1. distilBERT вивчив контекстні репрезентації слів з великого корпусу тексту. Це означає, що за допомогою ембедінгів ми додаємо більше контексту до наших даних.
2.  Секвенційні нейронні мережі добре підходять для секвенційних типів даних, чим є текст + мають більшу складність і capacity, ніж простіші моделі.
