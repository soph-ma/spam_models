{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логістична регресія "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'HTTP_PROXY=http://10.144.1.10:8080/ '\n",
    "os.environ['https_proxy'] = 'HTTPS_PROXY=http://10.144.1.10:8080/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import (get_x, get_y, tokenize_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenize_x(get_x())\n",
    "y = get_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float).view(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "input_dim = 25\n",
    "output_dim = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "     def __init__(self, input_dim, output_dim):\n",
    "         super(LogisticRegression, self).__init__()\n",
    "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "     def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Training Loss: 37.56047439575195, Validation Loss: 33.027069091796875\n",
      "Epoch: 2/100, Training Loss: 34.56238555908203, Validation Loss: 29.333694458007812\n",
      "Epoch: 3/100, Training Loss: 31.857528686523438, Validation Loss: 27.703554153442383\n",
      "Epoch: 4/100, Training Loss: 29.49394416809082, Validation Loss: 25.809852600097656\n",
      "Epoch: 5/100, Training Loss: 27.81968116760254, Validation Loss: 23.443328857421875\n",
      "Epoch: 6/100, Training Loss: 26.00849723815918, Validation Loss: 22.17647361755371\n",
      "Epoch: 7/100, Training Loss: 24.736053466796875, Validation Loss: 21.478273391723633\n",
      "Epoch: 8/100, Training Loss: 23.189212799072266, Validation Loss: 19.96458625793457\n",
      "Epoch: 9/100, Training Loss: 22.026399612426758, Validation Loss: 18.40545654296875\n",
      "Epoch: 10/100, Training Loss: 20.717071533203125, Validation Loss: 17.837322235107422\n",
      "Epoch: 11/100, Training Loss: 19.581762313842773, Validation Loss: 17.029876708984375\n",
      "Epoch: 12/100, Training Loss: 18.4271297454834, Validation Loss: 16.216402053833008\n",
      "Epoch: 13/100, Training Loss: 17.31477165222168, Validation Loss: 16.1740779876709\n",
      "Epoch: 14/100, Training Loss: 16.778173446655273, Validation Loss: 15.874299049377441\n",
      "Epoch: 15/100, Training Loss: 16.01934051513672, Validation Loss: 15.491232872009277\n",
      "Epoch: 16/100, Training Loss: 15.622748374938965, Validation Loss: 14.701821327209473\n",
      "Epoch: 17/100, Training Loss: 15.118365287780762, Validation Loss: 14.379549026489258\n",
      "Epoch: 18/100, Training Loss: 14.737918853759766, Validation Loss: 14.003376007080078\n",
      "Epoch: 19/100, Training Loss: 14.390044212341309, Validation Loss: 13.52334976196289\n",
      "Epoch: 20/100, Training Loss: 14.215025901794434, Validation Loss: 13.419153213500977\n",
      "Epoch: 21/100, Training Loss: 13.930158615112305, Validation Loss: 13.487329483032227\n",
      "Epoch: 22/100, Training Loss: 13.91202163696289, Validation Loss: 13.39793872833252\n",
      "Epoch: 23/100, Training Loss: 13.885177612304688, Validation Loss: 13.39712905883789\n",
      "Epoch: 24/100, Training Loss: 13.855067253112793, Validation Loss: 13.175307273864746\n",
      "Epoch: 25/100, Training Loss: 13.836136817932129, Validation Loss: 12.831069946289062\n",
      "Epoch: 26/100, Training Loss: 13.791421890258789, Validation Loss: 12.799910545349121\n",
      "Epoch: 27/100, Training Loss: 13.752110481262207, Validation Loss: 12.799042701721191\n",
      "Epoch: 28/100, Training Loss: 13.746916770935059, Validation Loss: 12.799042701721191\n",
      "Epoch: 29/100, Training Loss: 13.68697738647461, Validation Loss: 12.799042701721191\n",
      "Epoch: 30/100, Training Loss: 13.673151969909668, Validation Loss: 12.799783706665039\n",
      "Epoch: 31/100, Training Loss: 13.662856101989746, Validation Loss: 12.70586109161377\n",
      "Epoch: 32/100, Training Loss: 13.680225372314453, Validation Loss: 12.799410820007324\n",
      "Epoch: 33/100, Training Loss: 13.670673370361328, Validation Loss: 12.753833770751953\n",
      "Epoch: 34/100, Training Loss: 13.668375968933105, Validation Loss: 12.827717781066895\n",
      "Epoch: 35/100, Training Loss: 13.686981201171875, Validation Loss: 12.799042701721191\n",
      "Epoch: 36/100, Training Loss: 13.71274471282959, Validation Loss: 12.799042701721191\n",
      "Epoch: 37/100, Training Loss: 13.735280990600586, Validation Loss: 12.799042701721191\n",
      "Epoch: 38/100, Training Loss: 13.754007339477539, Validation Loss: 12.799042701721191\n",
      "Epoch: 39/100, Training Loss: 13.749428749084473, Validation Loss: 12.799042701721191\n",
      "Epoch: 40/100, Training Loss: 13.747047424316406, Validation Loss: 12.799042701721191\n",
      "Epoch: 41/100, Training Loss: 13.744959831237793, Validation Loss: 12.688996315002441\n",
      "Epoch: 42/100, Training Loss: 13.743058204650879, Validation Loss: 12.679974555969238\n",
      "Epoch: 43/100, Training Loss: 13.737300872802734, Validation Loss: 12.679430961608887\n",
      "Epoch: 44/100, Training Loss: 13.73924732208252, Validation Loss: 12.679426193237305\n",
      "Epoch: 45/100, Training Loss: 13.759345054626465, Validation Loss: 12.679426193237305\n",
      "Epoch: 46/100, Training Loss: 13.753920555114746, Validation Loss: 12.681292533874512\n",
      "Epoch: 47/100, Training Loss: 13.7450590133667, Validation Loss: 12.691227912902832\n",
      "Epoch: 48/100, Training Loss: 13.738158226013184, Validation Loss: 12.700515747070312\n",
      "Epoch: 49/100, Training Loss: 13.7064790725708, Validation Loss: 12.716947555541992\n",
      "Epoch: 50/100, Training Loss: 13.702291488647461, Validation Loss: 12.725844383239746\n",
      "Epoch: 51/100, Training Loss: 13.653016090393066, Validation Loss: 12.741490364074707\n",
      "Epoch: 52/100, Training Loss: 13.643362998962402, Validation Loss: 12.755706787109375\n",
      "Epoch: 53/100, Training Loss: 13.592033386230469, Validation Loss: 12.805717468261719\n",
      "Epoch: 54/100, Training Loss: 13.557334899902344, Validation Loss: 12.918660163879395\n",
      "Epoch: 55/100, Training Loss: 13.555795669555664, Validation Loss: 12.918660163879395\n",
      "Epoch: 56/100, Training Loss: 13.534757614135742, Validation Loss: 12.918660163879395\n",
      "Epoch: 57/100, Training Loss: 13.515304565429688, Validation Loss: 12.918660163879395\n",
      "Epoch: 58/100, Training Loss: 13.497821807861328, Validation Loss: 12.918660163879395\n",
      "Epoch: 59/100, Training Loss: 13.48059368133545, Validation Loss: 12.918660163879395\n",
      "Epoch: 60/100, Training Loss: 13.448206901550293, Validation Loss: 12.918660163879395\n",
      "Epoch: 61/100, Training Loss: 13.4375, Validation Loss: 12.919920921325684\n",
      "Epoch: 62/100, Training Loss: 13.390190124511719, Validation Loss: 12.987273216247559\n",
      "Epoch: 63/100, Training Loss: 13.389230728149414, Validation Loss: 13.038277626037598\n",
      "Epoch: 64/100, Training Loss: 13.385640144348145, Validation Loss: 13.038277626037598\n",
      "Epoch: 65/100, Training Loss: 13.3868989944458, Validation Loss: 13.038277626037598\n",
      "Epoch: 66/100, Training Loss: 13.384746551513672, Validation Loss: 13.038277626037598\n",
      "Epoch: 67/100, Training Loss: 13.366153717041016, Validation Loss: 13.038277626037598\n",
      "Epoch: 68/100, Training Loss: 13.33951187133789, Validation Loss: 13.038277626037598\n",
      "Epoch: 69/100, Training Loss: 13.336694717407227, Validation Loss: 13.038277626037598\n",
      "Epoch: 70/100, Training Loss: 13.344435691833496, Validation Loss: 13.038277626037598\n",
      "Epoch: 71/100, Training Loss: 13.326584815979004, Validation Loss: 13.019453048706055\n",
      "Epoch: 72/100, Training Loss: 13.313943862915039, Validation Loss: 13.010780334472656\n",
      "Epoch: 73/100, Training Loss: 13.310102462768555, Validation Loss: 13.00291919708252\n",
      "Epoch: 74/100, Training Loss: 13.284954071044922, Validation Loss: 12.981127738952637\n",
      "Epoch: 75/100, Training Loss: 13.280718803405762, Validation Loss: 12.961321830749512\n",
      "Epoch: 76/100, Training Loss: 13.276640892028809, Validation Loss: 12.944809913635254\n",
      "Epoch: 77/100, Training Loss: 13.27680778503418, Validation Loss: 12.940716743469238\n",
      "Epoch: 78/100, Training Loss: 13.27587604522705, Validation Loss: 12.94771671295166\n",
      "Epoch: 79/100, Training Loss: 13.273117065429688, Validation Loss: 12.959972381591797\n",
      "Epoch: 80/100, Training Loss: 13.25125503540039, Validation Loss: 12.988287925720215\n",
      "Epoch: 81/100, Training Loss: 13.247715950012207, Validation Loss: 12.992444038391113\n",
      "Epoch: 82/100, Training Loss: 13.248270034790039, Validation Loss: 12.99624252319336\n",
      "Epoch: 83/100, Training Loss: 13.248785972595215, Validation Loss: 12.999689102172852\n",
      "Epoch: 84/100, Training Loss: 13.249801635742188, Validation Loss: 13.00029182434082\n",
      "Epoch: 85/100, Training Loss: 13.227750778198242, Validation Loss: 12.999628067016602\n",
      "Epoch: 86/100, Training Loss: 13.228111267089844, Validation Loss: 12.995548248291016\n",
      "Epoch: 87/100, Training Loss: 13.218039512634277, Validation Loss: 12.958409309387207\n",
      "Epoch: 88/100, Training Loss: 13.215218544006348, Validation Loss: 12.934547424316406\n",
      "Epoch: 89/100, Training Loss: 13.192763328552246, Validation Loss: 12.918198585510254\n",
      "Epoch: 90/100, Training Loss: 13.185450553894043, Validation Loss: 12.89474105834961\n",
      "Epoch: 91/100, Training Loss: 13.179898262023926, Validation Loss: 12.871264457702637\n",
      "Epoch: 92/100, Training Loss: 13.177608489990234, Validation Loss: 12.85794448852539\n",
      "Epoch: 93/100, Training Loss: 13.186884880065918, Validation Loss: 12.842818260192871\n",
      "Epoch: 94/100, Training Loss: 13.175418853759766, Validation Loss: 12.818446159362793\n",
      "Epoch: 95/100, Training Loss: 13.171130180358887, Validation Loss: 12.80334758758545\n",
      "Epoch: 96/100, Training Loss: 13.17324447631836, Validation Loss: 12.799044609069824\n",
      "Epoch: 97/100, Training Loss: 13.173053741455078, Validation Loss: 12.799042701721191\n",
      "Epoch: 98/100, Training Loss: 13.173016548156738, Validation Loss: 12.799042701721191\n",
      "Epoch: 99/100, Training Loss: 13.1754789352417, Validation Loss: 12.799042701721191\n",
      "Epoch: 100/100, Training Loss: 13.17543888092041, Validation Loss: 12.79910659790039\n",
      "Best epoch:  43\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "accuracies_train = []\n",
    "accuracies_val = []\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    # loss\n",
    "    loss = criterion(outputs, y_train)\n",
    "    losses_train.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # accuracy\n",
    "    with torch.no_grad():\n",
    "        predicted = (outputs >= 0.5).squeeze().long()\n",
    "        accuracy = accuracy_score(y_train, predicted)\n",
    "        accuracies_train.append(accuracy)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_outputs = model(X_val)\n",
    "\n",
    "    # val loss\n",
    "    val_loss = criterion(val_outputs, y_val)\n",
    "    losses_val.append(val_loss)\n",
    "\n",
    "    # val accuracy\n",
    "    with torch.no_grad():\n",
    "        predicted_val = (val_outputs >= 0.5).squeeze().long() \n",
    "        accuracy_val = accuracy_score(y_val, predicted_val)\n",
    "        accuracies_val.append(accuracy_val)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        best_weights = model.state_dict()\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "print(\"Best epoch: \", best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to tensors\n",
    "losses_train = torch.tensor(losses_train)\n",
    "losses_val = torch.tensor(losses_val)\n",
    "accuracies_train = torch.tensor(accuracies_train)\n",
    "accuracies_val = torch.tensor(accuracies_val)\n",
    "\n",
    "# training and validation losses\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses_train.detach().numpy(), label='Training Loss')\n",
    "plt.plot(losses_val.detach().numpy(), label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# training and validation accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies_train.detach().numpy(), label='Training Accuracy')\n",
    "plt.plot(accuracies_val.detach().numpy(), label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики на тестових даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метрики*:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall \n",
    "- f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = model(X_test)\n",
    "test_outputs = (test_outputs >= 0.5).squeeze().long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, test_outputs)\n",
    "test_precision = precision_score(y_test, test_outputs)\n",
    "test_recall = recall_score(y_test, test_outputs)\n",
    "test_f1 = f1_score(y_test, test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8564593301435407\n",
      "Precision: 0.21428571428571427\n",
      "Recall: 0.026785714285714284\n",
      "f1: 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", test_precision)\n",
    "print(\"Recall:\", test_recall)\n",
    "print(\"f1:\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall and f1 близькі до 0. Це означає, що модель взагалі не визначає true positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
